{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/akamloo/ML-Practice/blob/master/Gradient_Descent.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "f2Sz2XND_K0p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IxxfcF_j_XCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_error_for_given_line_points(b,m,points):\n",
        "  total_error = 0\n",
        "  for i in range(0,len(points)):\n",
        "    x = points[i,0]\n",
        "    y = points[i,1]\n",
        "    total_error += (y - (m * x + b)) ** 2\n",
        "  return total_error/float(len(points))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITzFcxj6CItF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def step_gradient(m_current, b_current, points, learning_rate): # single-step optimization to reduce loss\n",
        "  m_gradient = 0\n",
        "  b_gradient = 0\n",
        "  N = len(points)\n",
        "  for i in range(0,len(points)):\n",
        "    x = points[i,0]\n",
        "    y = points[i,1]\n",
        "    \n",
        "    m_gradient += -(2 / N) * x * (y - ((m_current * x) + b_current)) #Partial derivation w.r.t. m\n",
        "    b_gradient += -(2 / N) * (y - ((m_current * x) + b_current)) #Partial derivation w.r.t. b\n",
        "    \n",
        "  new_b = b_current - (learning_rate * b_gradient) #optimise value of b\n",
        "  new_m = m_current - (learning_rate * m_gradient) #optimise value of m\n",
        "  return [new_b, new_m]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fzZ4XVKGFHXd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gradient_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
        "  b = starting_b\n",
        "  m = starting_m\n",
        "  for i in range(num_iterations):\n",
        "    b, m = step_gradient(m, b, array(points), learning_rate)\n",
        "  return [b, m]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HDWugLIF__V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQcQ6ZwlHhDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "088e3e12-df77-4670-ce26-dc43dfb354b2"
      },
      "cell_type": "code",
      "source": [
        "if __name__== '__main__':\n",
        "  learning_rate = 0.0001\n",
        "  points = genfromtxt(\"data.csv\", delimiter=\",\")\n",
        "  initial_b = 0   #initial y-intercept guess\n",
        "  initial_m = 0   #initial slope guess\n",
        "  num_iterations = 1000\n",
        "  print (\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, initial_m, compute_error_for_given_line_points(initial_b, initial_m, points)))\n",
        "  print (\"Running...\")\n",
        "  [b, m] = gradient_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
        "  print (\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b, m, compute_error_for_given_line_points(b, m, points)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting gradient descent at b = 0, m = 0, error = 5565.107834483211\n",
            "Running...\n",
            "After 1000 iterations b = 0.08893651993741346, m = 1.4777440851894448, error = 112.61481011613473\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
